<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>UBUS 670: Day 3 - Context Engineering</title>

    <!-- Fonts -->
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;500;600;700&display=swap">

    <!-- Reveal.js -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.0.4/reset.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.0.4/reveal.min.css">

    <!-- NIU Theme -->
    <link rel="stylesheet" href="../../_shared/reveal-theme-niu.css">

    <style>
        /* ============================================
           PERSISTENT NAVIGATION & BREADCRUMB
           ============================================ */
        .global-nav {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            z-index: 1000;
            background: rgba(255,255,255,0.98);
            border-bottom: 1px solid #e0e0e0;
            padding: 12px 24px;
            display: flex;
            justify-content: space-between;
            align-items: center;
            font-family: 'Montserrat', sans-serif;
            font-size: 14px;
        }
        .breadcrumb {
            display: flex;
            align-items: center;
            gap: 8px;
            color: #666;
        }
        .breadcrumb a {
            color: #1D428A;
            text-decoration: none;
            font-weight: 500;
        }
        .breadcrumb a:hover { text-decoration: underline; }
        .breadcrumb .separator { color: #ccc; }
        .breadcrumb .current { color: #333; font-weight: 600; }

        .nav-links {
            display: flex;
            gap: 8px;
        }
        .nav-links a {
            padding: 8px 16px;
            border-radius: 6px;
            text-decoration: none;
            font-weight: 600;
            transition: all 0.2s;
        }
        .nav-links a.primary {
            background: #C8102E;
            color: white;
        }
        .nav-links a.primary:hover { background: #a00d24; }
        .nav-links a.secondary {
            background: #f0f0f0;
            color: #333;
        }
        .nav-links a.secondary:hover { background: #e0e0e0; }

        /* Adjust slides to account for fixed nav */
        .reveal .slides { margin-top: 30px; }

        /* Shrink background images for breathing room */
        .reveal .slide-background-content {
            box-sizing: border-box;
            padding: 3% 2%;
            background-origin: content-box;
        }

        /* ============================================
           INTERACTIVE CHECKPOINT QUIZ (light style)
           ============================================ */
        .quiz-container {
            max-width: 860px;
            margin: 0 auto;
            text-align: left;
            color: #333;
        }
        .quiz-container h3 {
            font-family: 'Montserrat', sans-serif;
            font-size: 1.5em;
            margin-bottom: 20px;
            color: #1D428A;
        }
        .quiz-container .quiz-question {
            font-size: 1.05em;
            line-height: 1.5;
            margin-bottom: 25px;
            color: #333;
        }
        .quiz-options {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 14px;
        }
        .quiz-option {
            padding: 18px 22px;
            background: #ffffff;
            border: 2px solid #d0d5dd;
            border-radius: 10px;
            cursor: pointer;
            transition: all 0.2s;
            font-size: 0.95em;
            color: #333;
            font-family: 'Montserrat', sans-serif;
        }
        .quiz-option:hover {
            border-color: #1D428A;
            background: #f0f4fa;
        }
        .quiz-option.correct {
            border-color: #43B02A;
            background: rgba(67, 176, 42, 0.12);
            color: #2d7a1e;
        }
        .quiz-option.incorrect {
            border-color: #C8102E;
            background: rgba(200, 16, 46, 0.12);
            color: #a00d24;
        }
        .quiz-feedback {
            display: none;
            margin-top: 18px;
            padding: 14px 18px;
            border-radius: 8px;
            font-size: 0.9em;
        }
        .quiz-feedback.show { display: block; }
        .quiz-feedback.correct-fb {
            background: rgba(67, 176, 42, 0.1);
            color: #2d7a1e;
            border: 1px solid rgba(67, 176, 42, 0.3);
        }
        .quiz-feedback.incorrect-fb {
            background: rgba(200, 16, 46, 0.1);
            color: #a00d24;
            border: 1px solid rgba(200, 16, 46, 0.3);
        }
    </style>
</head>
<body>
    <!-- Persistent Navigation -->
    <div class="global-nav">
        <div class="breadcrumb">
            <a href="index.html">Day 3</a>
            <span class="separator">&rsaquo;</span>
            <span class="current">Lecture</span>
        </div>
        <div class="nav-links">
            <a href="index.html" class="secondary">Dashboard</a>
            <a href="lab.html" class="secondary">Lab</a>
            <a href="quiz.html" class="secondary">Quiz</a>
            <a href="day3-lecture.pdf" class="primary" target="_blank">PDF</a>
        </div>
    </div>

    <div class="reveal">
        <div class="slides">

            <!-- Slide 1: Title — Context Engineering -->
            <section data-background-image="images/slide-01.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Welcome to Day 3: Context Engineering. We're moving from asking questions to building information environments. Day 1 was "What is AI?", Day 2 was "Talk to AI" — today is "Give AI the right information to work with."</aside>
            </section>

            <!-- Slide 2: Learning Objectives -->
            <section data-background-image="images/slide-02.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Four objectives: (1) Explain context engineering and its business value, (2) Recognize structured formats — Markdown, JSON, (3) Describe RAG, embeddings, and vector databases conceptually, (4) Apply context engineering via Gemini Gems. Today's skill: moving from prompts to systems.</aside>
            </section>

            <!-- Slide 3: The Limitation of Prompts -->
            <section data-background-image="images/slide-03.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Beacon HR challenge: 200 applications to screen across 3 roles. The AI needs 50+ pages of policies, legal guidelines, and brand voice. That's too much for a single prompt. Imagine hiring a brilliant consultant but only giving them a one-sentence brief — that's what we've been doing.</aside>
            </section>

            <!-- Slide 4: The Context Stack -->
            <section data-background-image="images/slide-04.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Context engineering is building an information environment, not just asking a question. Three layers: (1) The Prompt — your immediate question, (2) Documents — reference materials like policies, reports, data, (3) Instructions — system-level guidelines on how to behave. Together these create a comprehensive context.</aside>
            </section>

            <!-- Slide 5: Structure Helps AI Think Better -->
            <section data-background-image="images/slide-05.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Modern AI can read messy text — scanned PDFs, handwritten notes, complex tables. But structure reduces ambiguity and produces more consistent results. Analogy: organized desk vs. messy desk. You can find things on both, but you'll find them faster and more reliably on the organized one.</aside>
            </section>

            <!-- Slide 6: Meet the Formats — Markdown -->
            <section data-background-image="images/slide-06.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Markdown is a simple way to add structure to plain text. Left: a paragraph about vacation policy — hard to parse. Right: the same info with headings, bold labels, bullet points. These are "signposts for the AI." You may already use some of these patterns without knowing it. # = heading, **bold** = bold, - = bullet.</aside>
            </section>

            <!-- Slide 7: Other Formats — JSON & XML -->
            <section data-background-image="images/slide-07.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Two other structured formats to recognize. JSON: key-value pairs used by APIs and web apps. XML: tagged data used by enterprise systems, government, healthcare. You don't need to write code — just recognize that structure = clarity for AI. When your tech team says "the AI returns JSON," now you know what that means.</aside>
            </section>

            <!-- INTERACTIVE: Checkpoint Quiz — Structure -->
            <section data-background-color="#f5f7fa">
                <div class="quiz-container" id="quiz1">
                    <h3>Checkpoint: Why Structure Matters</h3>
                    <p class="quiz-question">Beacon's HR team uploads a 30-page employee handbook to Gemini. The handbook is one long paragraph with no headings, bullets, or formatting. What's the most likely result?</p>
                    <div class="quiz-options">
                        <div class="quiz-option" onclick="checkQuiz(this, 'quiz1', false)">A) Gemini can't read it at all</div>
                        <div class="quiz-option" onclick="checkQuiz(this, 'quiz1', true)">B) It works, but answers are less precise and harder to verify</div>
                        <div class="quiz-option" onclick="checkQuiz(this, 'quiz1', false)">C) Gemini automatically adds Markdown formatting</div>
                        <div class="quiz-option" onclick="checkQuiz(this, 'quiz1', false)">D) The file is too large to upload</div>
                    </div>
                    <div class="quiz-feedback" id="quiz1-feedback-correct">
                        <strong>Correct!</strong> Modern AI can read unstructured text, but structure helps it find information faster, produce more precise answers, and makes it easier for you to verify the output.
                    </div>
                    <div class="quiz-feedback" id="quiz1-feedback-incorrect">
                        <strong>Not quite.</strong> AI can read unstructured text — it just produces less precise, harder-to-verify results. Structure helps AI navigate documents more reliably. Try again!
                    </div>
                </div>
            </section>

            <!-- Slide 8: Chunking — Managing Attention -->
            <section data-background-image="images/slide-08.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Even with massive context windows, chunking matters. Breaking a 200-page handbook into sections — Vacation Policy, Remote Work, Benefits — helps AI focus on what's relevant. NotebookLM does this automatically when you upload documents. Chunking reduces cost and improves retrieval accuracy.</aside>
            </section>

            <!-- Slide 9: Three Strategies for Chunking -->
            <section data-background-image="images/slide-09.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Three strategies: (1) Semantic Section — split by topic/chapters, best for most business docs. (2) Fixed Size — every 500 words with overlap, use when docs lack clear structure. (3) Task Relevance — upload only what's needed for the current question, fastest and cheapest. Also: the Inverted Pyramid Rule — AI pays most attention to the beginning and end of a file.</aside>
            </section>

            <!-- Slide 10: RAG — Retrieval-Augmented Generation -->
            <section data-background-image="images/slide-10.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">RAG is a two-step process: Retrieval (search your documents for relevant chunks) + Generation (feed those chunks to the LLM to write an informed answer). Key benefit: the AI doesn't memorize everything — it looks it up when needed, just like you'd reference a manual. This grounds the AI in your data and reduces hallucinations.</aside>
            </section>

            <!-- Slide 11: Open vs. Closed Book Analogy -->
            <section data-background-image="images/slide-11.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Closed Book (Traditional AI): "I only know what I studied years ago." Relies on memorized training data, hallucinations when unsure, knowledge cutoff. Open Book (RAG): "I can find the latest information instantly!" Uses your proprietary data, more accurate, always current. RAG turns AI from a "know-it-all" into a "know-where-to-look" system.</aside>
            </section>

            <!-- Slide 12: Embeddings — Search by Meaning -->
            <section data-background-image="images/slide-12.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Embeddings convert text into numbers (vectors) that capture meaning. In this vector space, "Late Package" clusters near "Shipping Delay" and "Delivery Issue" — because they mean similar things. RAG finds "Late Package" even if you search for "Shipping Delay" because they're close in mathematical space. This is semantic search — much more powerful than keyword matching (Ctrl+F).</aside>
            </section>

            <!-- Slide 13: Vector Databases -->
            <section data-background-image="images/slide-13.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Vector databases are the AI filing cabinet — they store "meanings" (embeddings) instead of just keywords. Products to know: Pinecone, Weaviate, Chroma. Business analogy: a regular filing cabinet finds files by label; a vector database finds files by what they're about — even if the labels are different. You don't build this; your engineers do. You just need to know it's the engine.</aside>
            </section>

            <!-- Slide 14: How RAG Works — The Architecture -->
            <section data-background-image="images/slide-14.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">The RAG pipeline: User Question → Retriever searches the vector database → Relevant Chunks are pulled → LLM reads the chunks and generates a natural language Answer. Walk through this slowly. The retriever is doing semantic search using embeddings. The LLM never sees your full document library — only the most relevant pieces.</aside>
            </section>

            <!-- INTERACTIVE: Checkpoint Quiz — RAG -->
            <section data-background-color="#f5f7fa">
                <div class="quiz-container" id="quiz2">
                    <h3>Checkpoint: RAG in Action</h3>
                    <p class="quiz-question">Beacon builds a RAG-powered chatbot for customer service. A customer asks, &ldquo;What's your return policy for electronics?&rdquo; What happens first?</p>
                    <div class="quiz-options">
                        <div class="quiz-option" onclick="checkQuiz(this, 'quiz2', false)">A) The LLM writes an answer from its training data</div>
                        <div class="quiz-option" onclick="checkQuiz(this, 'quiz2', true)">B) The retriever searches Beacon's documents for relevant return policy sections</div>
                        <div class="quiz-option" onclick="checkQuiz(this, 'quiz2', false)">C) The chatbot asks the customer to rephrase the question</div>
                        <div class="quiz-option" onclick="checkQuiz(this, 'quiz2', false)">D) The system sends the question to a human agent</div>
                    </div>
                    <div class="quiz-feedback" id="quiz2-feedback-correct">
                        <strong>Correct!</strong> In RAG, retrieval comes first. The system searches Beacon's documents for relevant chunks about the return policy, then feeds those chunks to the LLM to generate an accurate, grounded answer.
                    </div>
                    <div class="quiz-feedback" id="quiz2-feedback-incorrect">
                        <strong>Not quite.</strong> RAG is a two-step process: Retrieve first, then Generate. The retriever searches your documents before the LLM writes anything. Try again!
                    </div>
                </div>
            </section>

            <!-- Slide 15: Why RAG Matters for Business -->
            <section data-background-image="images/slide-15.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Four business benefits: (1) Reduces Hallucinations — grounds answers in real documents, cites sources. (2) Keeps AI Current — update docs, update knowledge instantly. Your Q4 numbers? Available immediately. (3) Proprietary Data — works with your policies, customers, products. (4) Auditable — trace the decision, critical for compliance. This is the difference between a chatbot that "sounds smart" and one that's actually useful.</aside>
            </section>

            <!-- Slide 16: RAG vs. Fine-Tuning -->
            <section data-background-image="images/slide-16.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">RAG: adds knowledge, like giving someone a textbook, low cost, instant updates. Fine-tuning: changes behavior, like sending someone to med school, high cost, slow updates. For 95% of business cases in 2026, use RAG. General models like Gemini 2.5 are now smart enough that fine-tuning is only needed for highly specialized domains.</aside>
            </section>

            <!-- Slide 17: The Accidental Fine-Tuner -->
            <section data-background-image="images/slide-17.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Story time: Dr. Chen, an accounting professor, created a Custom ChatGPT to train auditors in empathetic listening. She repeatedly corrected the AI — "Stop solving! Just listen and empathize." Over weeks, it became a remarkably good listener. She thought she had "trained" the model to be empathetic by correcting it for weeks.</aside>
            </section>

            <!-- Slide 18: The Twist -->
            <section data-background-image="images/slide-18.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Dr. Chen hired a developer to extract her "fine-tuned model" and deploy it as a standalone app. But when the developer looked inside... there were no modified weights. The model weights were locked. She hadn't actually fine-tuned anything. So what happened?</aside>
            </section>

            <!-- Slide 19: What Really Happened -->
            <section data-background-image="images/slide-19.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Custom ChatGPTs and Gemini Gems do NOT modify model weights. They use: (1) Instructions — a system prompt telling AI how to behave, (2) Memory — stored conversation history, (3) Knowledge/RAG — uploaded documents. The frozen brain (model weights) stays locked. Behavioral configuration does NOT equal fine-tuning. The good news: YOU can do this too, without any technical expertise!</aside>
            </section>

            <!-- Slide 20: Your Tool — Gemini Gems -->
            <section data-background-image="images/slide-20.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">Gemini Gems: no-code RAG in action. Features: persistent knowledge (upload 10 files), custom instructions ("Act as HR Assistant"), shareable links with colleagues. This is free on personal Google accounts. Today in the lab, you'll build a Beacon Knowledge Assistant using a Gem.</aside>
            </section>

            <!-- Slide 21: Lab Prep — The Experiment -->
            <section data-background-image="images/slide-21.png" data-background-size="contain" data-background-color="#ffffff">
                <aside class="notes">The lab experiment: three modes to compare. (1) No Context — raw Gemini, no uploads. (2) Upload to Chat — attach files temporarily in one conversation. (3) Gemini Gem — persistent system with knowledge and instructions. Open your laptops and head to gemini.google.com. Let's see how context changes everything.</aside>
            </section>

        </div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.0.4/reveal.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/reveal.js/5.0.4/plugin/notes/notes.min.js"></script>
    <script>
        Reveal.initialize({
            hash: true,
            slideNumber: 'c/t',
            showSlideNumber: 'all',
            progress: true,
            controls: true,
            controlsTutorial: false,
            transition: 'slide',
            plugins: [ RevealNotes ]
        });

        // Interactive checkpoint quiz handler
        function checkQuiz(element, quizId, isCorrect) {
            var container = document.getElementById(quizId);
            var options = container.querySelectorAll('.quiz-option');
            var feedbackCorrect = document.getElementById(quizId + '-feedback-correct');
            var feedbackIncorrect = document.getElementById(quizId + '-feedback-incorrect');

            // Reset all options
            options.forEach(function(opt) {
                opt.classList.remove('correct', 'incorrect');
            });

            // Hide both feedbacks
            feedbackCorrect.style.display = 'none';
            feedbackCorrect.classList.remove('correct-fb', 'incorrect-fb', 'show');
            feedbackIncorrect.style.display = 'none';
            feedbackIncorrect.classList.remove('correct-fb', 'incorrect-fb', 'show');

            if (isCorrect) {
                element.classList.add('correct');
                feedbackCorrect.style.display = 'block';
                feedbackCorrect.classList.add('correct-fb', 'show');
            } else {
                element.classList.add('incorrect');
                feedbackIncorrect.style.display = 'block';
                feedbackIncorrect.classList.add('incorrect-fb', 'show');
            }
        }
    </script>
</body>
</html>
